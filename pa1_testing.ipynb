{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for testing development of pa1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test\n",
    "test.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test knn.py\n",
    "from data import data_processing\n",
    "from utils import Distances, HyperparameterTuner, MinMaxScaler, f1_score, NormalizationScaler\n",
    "from knn import KNN\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "distance_funcs = {\n",
    "    'canberra': Distances.canberra_distance,\n",
    "    'minkowski': Distances.minkowski_distance,\n",
    "    'euclidean': Distances.euclidean_distance,\n",
    "    'gaussian': Distances.gaussian_kernel_distance,\n",
    "    'inner_prod': Distances.inner_product_distance,\n",
    "    'cosine_dist': Distances.cosine_similarity_distance,\n",
    "}\n",
    "\n",
    "scaling_classes = {\n",
    "    'min_max_scale': MinMaxScaler,\n",
    "    'normalize': NormalizationScaler,\n",
    "}\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = data_processing()\n",
    "len(x_train)\n",
    "#x_train[:1] = 0\n",
    "#print(x_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated k: 1, updated distance function: canberra                        , updated scaler: min_max_scale, updated f1: 0.7755102040816326\n",
      "updated k: 3, updated distance function: canberra                        , updated scaler: min_max_scale, updated f1: 0.8571428571428572\n",
      "best k: 3, best distance function: canberra, from model:3,         <function Distances.canberra_distance at 0x113bf66a8>\n"
     ]
    }
   ],
   "source": [
    "# test tuning functions\n",
    "tuner_without_scaling_obj = HyperparameterTuner()\n",
    "tuner_without_scaling_obj.tuning_with_scaling(distance_funcs, scaling_classes, x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of k values\n",
    "k_array = np.arange(1, 30, 2)\n",
    "\n",
    "# initialize f1 score\n",
    "f1score = 0\n",
    "\n",
    "# loop through k values\n",
    "for k in k_array:\n",
    "\n",
    "    # loop through distance functions\n",
    "    for key in distance_funcs:\n",
    "\n",
    "        # run KNN\n",
    "        knn_instance = KNN(k, distance_funcs[key]) # initiate knn object\n",
    "        knn_instance.train(x_train, y_train) # train model\n",
    "        y_val_predicted = knn_instance.predict(x_val) # returns predicted labels\n",
    "\n",
    "        # compute f1 score for this knn instance\n",
    "        this_f1score = f1_score(y_val, y_val_predicted)\n",
    "\n",
    "        if this_f1score > f1score:\n",
    "            f1score = this_f1score # update best f1 score \n",
    "            best_k = k # update best k\n",
    "            best_distance_function = key # update best distance function\n",
    "            best_model = knn_instance # update best knn model\n",
    "\n",
    "# You need to assign the final values to these variables\n",
    "print(f'best k: {best_k}')\n",
    "print(f'best distance function: {best_distance_function}')\n",
    "print(f'best model: {best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of k values\n",
    "k_array = np.arange(1, 30, 2)\n",
    "\n",
    "# initialize variables\n",
    "f1score = 0\n",
    "\n",
    "# loop through k values\n",
    "for k in k_array:\n",
    "\n",
    "    # loop through distance functions\n",
    "    for key in distance_funcs:\n",
    "\n",
    "        # loop through scalers\n",
    "        for scaler in scaling_classes: \n",
    "\n",
    "            # scale data \n",
    "            scaler_function = scaling_classes[scaler]\n",
    "            scaler_obj = scaler_function()\n",
    "            x_train = scaler_obj(x_train)\n",
    "            x_val = scaler_obj(x_val)\n",
    "\n",
    "            # run KNN\n",
    "            knn_instance = KNN(k, distance_funcs[key]) # initiate knn object\n",
    "            knn_instance.train(x_train, y_train) # train model\n",
    "            y_val_predicted = knn_instance.predict(x_val) # returns predicted labels\n",
    "\n",
    "            # compute f1 score for this knn instance\n",
    "            this_f1score = f1_score(y_val, y_val_predicted)\n",
    "\n",
    "            if this_f1score > f1score:\n",
    "                f1score = this_f1score # update best f1 score \n",
    "                best_k = k # update best k\n",
    "                best_distance_function = key # update best distance function\n",
    "                best_model = knn_instance # update best knn model\n",
    "                best_scaler = scaler # update scaler\n",
    "\n",
    "# Print values\n",
    "print(f'best k: {best_k}')\n",
    "print(f'best distance function: {best_distance_function}')\n",
    "print(f'self.best_scaler: {best_scaler}')\n",
    "print(f'best model: {best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_k_neighbors(self, point):\n",
    "knn_obj = KNN(7, Distances.canberra_distance)\n",
    "knn_obj.train(x_train, y_train)\n",
    "test_obj = knn_obj\n",
    "print(test_obj.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,(len(x_test))): \n",
    "    output = knn_obj.get_k_neighbors(x_test[i])\n",
    "    print(output)\n",
    "    print(len(output))\n",
    "    print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train shape = ', x_train.shape)\n",
    "print('y_train shape = ', y_train.shape)\n",
    "\n",
    "tuner_without_scaling_obj = HyperparameterTuner()\n",
    "tuner_without_scaling_obj.tuning_without_scaling(distance_funcs, x_train, y_train, x_val, y_val)\n",
    "\n",
    "print(\"**Without Scaling**\")\n",
    "print(\"k =\", tuner_without_scaling_obj.best_k)\n",
    "print(\"distance function =\", tuner_without_scaling_obj.best_distance_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import NormalizationScaler\n",
    "features = [[3.0, 4.0], [1.0, -1.0], [0.0, 0.0]]\n",
    "print(features)\n",
    "print(type(features[0][0]))\n",
    "print(np.empty(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [[3.0, 4.0], [1.0, -1.0], [0.0, 0.0]]\n",
    "scaled_features = []\n",
    "norm = np.sqrt(Distances.inner_product_distance(features[0], features[0]))\n",
    "scaled1 = features[0]/norm\n",
    "scaled_features.append(scaled1)\n",
    "\n",
    "norm = np.sqrt(Distances.inner_product_distance(features[1], features[1]))\n",
    "print(type(norm))\n",
    "scaled2 = [features[1]/norm]\n",
    "print(type(features[1]))\n",
    "print(type(scaled2))\n",
    "scaled_features.append(scaled2)\n",
    "\n",
    "scaled3 = features[2]\n",
    "scaled_features.append(scaled3)\n",
    "print(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = NormalizationScaler()\n",
    "norm = np.sqrt(Distances.inner_product_distance(features[1], features[1]))\n",
    "scaled = features[1]/norm\n",
    "print(norm)\n",
    "print(scaled)\n",
    "result = normalize(features)\n",
    "print(result)\n",
    "print(len(result))\n",
    "print(type(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [[2, -1], [-1, 5], [0, 0]]\n",
    "features = np.array(features)\n",
    "print(features)\n",
    "features_max = features.max(axis=0)\n",
    "features_min = features.min(axis=0)\n",
    "print(features_max)\n",
    "print(features_min)\n",
    "columns = features.shape[1]\n",
    "for i in range(columns):\n",
    "    features[:,i] = (features[:,i]-features_min[i])/(features_max[i]-features_min[i])\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [[0, 10], [2, 0]]\n",
    "test_features = [[20, 1]]\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "train_features_scaled = scaler1(train_features)\n",
    "print(train_features_scaled)\n",
    "# train_features_scaled should be equal to [[0, 1], [1, 0]]\n",
    "\n",
    "test_features_scaled = scaler1(test_features)\n",
    "print(test_features_scaled)\n",
    "# test_features_scaled should be equal to [[10, 0.1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test.py provided from startup package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import data_processing\n",
    "from utils import Distances, HyperparameterTuner, MinMaxScaler, f1_score, NormalizationScaler\n",
    "from knn import KNN\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "distance_funcs = {\n",
    "    'canberra': Distances.canberra_distance,\n",
    "    'minkowski': Distances.minkowski_distance,\n",
    "    'euclidean': Distances.euclidean_distance,\n",
    "    'gaussian': Distances.gaussian_kernel_distance,\n",
    "    'inner_prod': Distances.inner_product_distance,\n",
    "    'cosine_dist': Distances.cosine_similarity_distance,\n",
    "}\n",
    "\n",
    "scaling_classes = {\n",
    "    'min_max_scale': MinMaxScaler,\n",
    "    'normalize': NormalizationScaler,\n",
    "}\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = data_processing()\n",
    "x_train = x_train*[0]\n",
    "y_train = y_train*[0]\n",
    "x_val = x_val*[0]\n",
    "y_val = y_val*[0]\n",
    "x_test = x_test*[0]\n",
    "y_test = y_test*[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_without_scaling_obj = HyperparameterTuner()\n",
    "tuner_without_scaling_obj.tuning_without_scaling(distance_funcs, x_train, y_train, x_val, y_val)\n",
    "\n",
    "print(\"**Without Scaling**\")\n",
    "print(\"k =\", tuner_without_scaling_obj.best_k)\n",
    "print(\"distance function =\", tuner_without_scaling_obj.best_distance_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_with_scaling_obj = HyperparameterTuner()\n",
    "tuner_with_scaling_obj.tuning_with_scaling(distance_funcs, scaling_classes, x_train, y_train, x_val, y_val)\n",
    "\n",
    "print(\"\\n**With Scaling**\")\n",
    "print(\"k =\", tuner_with_scaling_obj.best_k)\n",
    "print(\"distance function =\", tuner_with_scaling_obj.best_distance_function)\n",
    "print(\"scaler =\", tuner_with_scaling_obj.best_scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
